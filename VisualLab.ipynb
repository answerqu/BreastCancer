{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score, confusion_matrix,accuracy_score\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.preprocessing import *\n",
    "from functions.functions import *\n",
    "from functions.df_modifications import *\n",
    "from functions.feature_selection import *\n",
    "from functions.other import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_df = 'vl'\n",
    "type_of_mask = 'v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pathology</th>\n",
       "      <th>f_1_1_10__left__v1</th>\n",
       "      <th>f_1_1_10__right__v1</th>\n",
       "      <th>f_1_1_10__v1</th>\n",
       "      <th>f_1_1_1__left__v1</th>\n",
       "      <th>f_1_1_1__right__v1</th>\n",
       "      <th>f_1_1_1__v1</th>\n",
       "      <th>f_1_1_2__left__v1</th>\n",
       "      <th>f_1_1_2__right__v1</th>\n",
       "      <th>f_1_1_2__v1</th>\n",
       "      <th>...</th>\n",
       "      <th>f_4_5_4__v1__(bw_3)__2_3</th>\n",
       "      <th>f_4_5_4__v1__(bw_3)__2_4</th>\n",
       "      <th>f_4_5_4__v1__(bw_3)__2_5</th>\n",
       "      <th>f_4_5_4__v1__(bw_3)__3_0</th>\n",
       "      <th>f_4_5_4__v1__(bw_3)__3_1</th>\n",
       "      <th>f_4_5_4__v1__(bw_3)__3_2</th>\n",
       "      <th>f_4_5_4__v1__(bw_3)__3_3</th>\n",
       "      <th>f_4_5_4__v1__(bw_3)__3_4</th>\n",
       "      <th>f_4_5_4__v1__(bw_3)__3_5</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PAC_00_DN0_RAW</th>\n",
       "      <td>1</td>\n",
       "      <td>153.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>128.465223</td>\n",
       "      <td>128.465223</td>\n",
       "      <td>127.877683</td>\n",
       "      <td>19.200861</td>\n",
       "      <td>19.200861</td>\n",
       "      <td>19.067926</td>\n",
       "      <td>...</td>\n",
       "      <td>122.665680</td>\n",
       "      <td>127.715976</td>\n",
       "      <td>126.991124</td>\n",
       "      <td>45.464497</td>\n",
       "      <td>43.905325</td>\n",
       "      <td>44.529586</td>\n",
       "      <td>45.517751</td>\n",
       "      <td>44.529586</td>\n",
       "      <td>43.905325</td>\n",
       "      <td>PAC_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAC_00_DN10_RAW</th>\n",
       "      <td>1</td>\n",
       "      <td>173.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>145.996855</td>\n",
       "      <td>145.996855</td>\n",
       "      <td>145.996855</td>\n",
       "      <td>20.726065</td>\n",
       "      <td>20.726065</td>\n",
       "      <td>20.726065</td>\n",
       "      <td>...</td>\n",
       "      <td>101.460000</td>\n",
       "      <td>113.042857</td>\n",
       "      <td>114.534286</td>\n",
       "      <td>24.182857</td>\n",
       "      <td>23.397143</td>\n",
       "      <td>23.517143</td>\n",
       "      <td>22.822857</td>\n",
       "      <td>23.517143</td>\n",
       "      <td>23.397143</td>\n",
       "      <td>PAC_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAC_00_DN11_RAW</th>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>144.972555</td>\n",
       "      <td>144.972555</td>\n",
       "      <td>144.972555</td>\n",
       "      <td>19.626635</td>\n",
       "      <td>19.626635</td>\n",
       "      <td>19.626635</td>\n",
       "      <td>...</td>\n",
       "      <td>103.038690</td>\n",
       "      <td>111.217262</td>\n",
       "      <td>112.517857</td>\n",
       "      <td>24.818452</td>\n",
       "      <td>21.264881</td>\n",
       "      <td>21.199405</td>\n",
       "      <td>24.181548</td>\n",
       "      <td>21.199405</td>\n",
       "      <td>21.264881</td>\n",
       "      <td>PAC_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAC_00_DN12_RAW</th>\n",
       "      <td>1</td>\n",
       "      <td>173.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>146.945692</td>\n",
       "      <td>146.945692</td>\n",
       "      <td>146.809036</td>\n",
       "      <td>20.425921</td>\n",
       "      <td>20.425921</td>\n",
       "      <td>20.360977</td>\n",
       "      <td>...</td>\n",
       "      <td>90.267442</td>\n",
       "      <td>100.476744</td>\n",
       "      <td>98.279070</td>\n",
       "      <td>19.351744</td>\n",
       "      <td>18.104651</td>\n",
       "      <td>17.715116</td>\n",
       "      <td>20.043605</td>\n",
       "      <td>17.715116</td>\n",
       "      <td>18.104651</td>\n",
       "      <td>PAC_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAC_00_DN13_RAW</th>\n",
       "      <td>1</td>\n",
       "      <td>176.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>148.365707</td>\n",
       "      <td>148.365707</td>\n",
       "      <td>148.365707</td>\n",
       "      <td>20.948782</td>\n",
       "      <td>20.948782</td>\n",
       "      <td>20.948782</td>\n",
       "      <td>...</td>\n",
       "      <td>96.054755</td>\n",
       "      <td>106.556196</td>\n",
       "      <td>106.340058</td>\n",
       "      <td>18.501441</td>\n",
       "      <td>16.253602</td>\n",
       "      <td>16.389049</td>\n",
       "      <td>19.242075</td>\n",
       "      <td>16.389049</td>\n",
       "      <td>16.253602</td>\n",
       "      <td>PAC_00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1867 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pathology  f_1_1_10__left__v1  f_1_1_10__right__v1  \\\n",
       "PAC_00_DN0_RAW           1               153.0                153.0   \n",
       "PAC_00_DN10_RAW          1               173.0                173.0   \n",
       "PAC_00_DN11_RAW          1               171.0                171.0   \n",
       "PAC_00_DN12_RAW          1               173.0                173.0   \n",
       "PAC_00_DN13_RAW          1               176.0                176.0   \n",
       "\n",
       "                 f_1_1_10__v1  f_1_1_1__left__v1  f_1_1_1__right__v1  \\\n",
       "PAC_00_DN0_RAW          152.0         128.465223          128.465223   \n",
       "PAC_00_DN10_RAW         173.0         145.996855          145.996855   \n",
       "PAC_00_DN11_RAW         171.0         144.972555          144.972555   \n",
       "PAC_00_DN12_RAW         173.0         146.945692          146.945692   \n",
       "PAC_00_DN13_RAW         176.0         148.365707          148.365707   \n",
       "\n",
       "                 f_1_1_1__v1  f_1_1_2__left__v1  f_1_1_2__right__v1  \\\n",
       "PAC_00_DN0_RAW    127.877683          19.200861           19.200861   \n",
       "PAC_00_DN10_RAW   145.996855          20.726065           20.726065   \n",
       "PAC_00_DN11_RAW   144.972555          19.626635           19.626635   \n",
       "PAC_00_DN12_RAW   146.809036          20.425921           20.425921   \n",
       "PAC_00_DN13_RAW   148.365707          20.948782           20.948782   \n",
       "\n",
       "                 f_1_1_2__v1  ...  f_4_5_4__v1__(bw_3)__2_3  \\\n",
       "PAC_00_DN0_RAW     19.067926  ...                122.665680   \n",
       "PAC_00_DN10_RAW    20.726065  ...                101.460000   \n",
       "PAC_00_DN11_RAW    19.626635  ...                103.038690   \n",
       "PAC_00_DN12_RAW    20.360977  ...                 90.267442   \n",
       "PAC_00_DN13_RAW    20.948782  ...                 96.054755   \n",
       "\n",
       "                 f_4_5_4__v1__(bw_3)__2_4  f_4_5_4__v1__(bw_3)__2_5  \\\n",
       "PAC_00_DN0_RAW                 127.715976                126.991124   \n",
       "PAC_00_DN10_RAW                113.042857                114.534286   \n",
       "PAC_00_DN11_RAW                111.217262                112.517857   \n",
       "PAC_00_DN12_RAW                100.476744                 98.279070   \n",
       "PAC_00_DN13_RAW                106.556196                106.340058   \n",
       "\n",
       "                 f_4_5_4__v1__(bw_3)__3_0  f_4_5_4__v1__(bw_3)__3_1  \\\n",
       "PAC_00_DN0_RAW                  45.464497                 43.905325   \n",
       "PAC_00_DN10_RAW                 24.182857                 23.397143   \n",
       "PAC_00_DN11_RAW                 24.818452                 21.264881   \n",
       "PAC_00_DN12_RAW                 19.351744                 18.104651   \n",
       "PAC_00_DN13_RAW                 18.501441                 16.253602   \n",
       "\n",
       "                 f_4_5_4__v1__(bw_3)__3_2  f_4_5_4__v1__(bw_3)__3_3  \\\n",
       "PAC_00_DN0_RAW                  44.529586                 45.517751   \n",
       "PAC_00_DN10_RAW                 23.517143                 22.822857   \n",
       "PAC_00_DN11_RAW                 21.199405                 24.181548   \n",
       "PAC_00_DN12_RAW                 17.715116                 20.043605   \n",
       "PAC_00_DN13_RAW                 16.389049                 19.242075   \n",
       "\n",
       "                 f_4_5_4__v1__(bw_3)__3_4  f_4_5_4__v1__(bw_3)__3_5      id  \n",
       "PAC_00_DN0_RAW                  44.529586                 43.905325  PAC_00  \n",
       "PAC_00_DN10_RAW                 23.517143                 23.397143  PAC_00  \n",
       "PAC_00_DN11_RAW                 21.199405                 21.264881  PAC_00  \n",
       "PAC_00_DN12_RAW                 17.715116                 18.104651  PAC_00  \n",
       "PAC_00_DN13_RAW                 16.389049                 16.253602  PAC_00  \n",
       "\n",
       "[5 rows x 1867 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(f'data/TG_{type_of_df}.parquet')\n",
    "df.columns = [col.replace('__gen', '') for col in df.columns]\n",
    "df.index = [ind.replace('_pat','').replace('_non','') for ind in df.index]\n",
    "df['id'] = df.index.map(lambda x: x.split('_')[0] + '_' + x.split('_')[1])\n",
    "df1 = df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.copy()\n",
    "df_non_symm = df[(df.f_1_1_1__right__v1 != df.f_1_1_1__left__v1) | (df.pathology == 0)]\n",
    "df_symm = df[(df.f_1_1_1__right__v1 == df.f_1_1_1__v1).values & (df.f_1_1_1__left__v1 == df.f_1_1_1__v1).values]\n",
    "\n",
    "df_non_symm = split_areas(df_non_symm)\n",
    "df_symm = split_areas(df_symm)\n",
    "df_symm = df_symm.loc[[ind for ind in df_symm.index if ind.find('right') != -1], :]\n",
    "\n",
    "df = pd.concat([df_symm,df_non_symm],axis=0)\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = ['PAC_69','PAC_48','PAC_14','PAC_65','PAC_63','PAC_66','PAC_61','PAC_64','PAC_62']\n",
    "#df = df[[col for col in df.columns if col.find('f_1') != -1 or col.find('f_4') != -1 ] + ['id', 'pathology']]\n",
    "df_test = df[df.id.isin(test_id)]\n",
    "df = df.drop(df_test.index)\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pathology\n",
    "X = df.iloc[:,:-2]\n",
    "id_column = df.id\n",
    "\n",
    "y_control = df_test.pathology\n",
    "X_control = df_test.iloc[:,:-2]\n",
    "X1 = X.copy()\n",
    "\n",
    "#cols = [col for col in X.columns if col.find('f_3') == -1 and col.find('f_2') == -1]\n",
    "\n",
    "#X = X[cols]\n",
    "#X_control = X_control[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_round(X_train, X_test, X_control):\n",
    "    X_train,q1 = variance(X_train)\n",
    "    X_train,q2 = outliers(X_train)\n",
    "    X_train = correlation(X_train, thr=0.95)\n",
    "    return X_train, X_test[X_train.columns], X_control[X_train.columns]\n",
    "\n",
    "\n",
    "second_round = [ttest, pca, permut, lr_selection, boruta_selection, greedy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_control_main = X_control.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n=5\n",
    "N=10\n",
    "\n",
    "res = {}\n",
    "for s in range(N):\n",
    "    res[f'split_{s}'] = {}\n",
    "    for func in second_round:\n",
    "        res[f'split_{s}'][func.__name__] = {}\n",
    "        for model_name in ['lr', 'svm', 'rf', 'xgb']:\n",
    "            res[f'split_{s}'][func.__name__][model_name] = {}\n",
    "            for metric in ['acc_test', 'auc_test', 'acc_control', 'auc_control']:\n",
    "                res[f'split_{s}'][func.__name__][model_name][metric] = []\n",
    "        res[f'split_{s}'][func.__name__]['n_features'] = []\n",
    "\n",
    "for s in tqdm(range(N)):   \n",
    "    X_fold, y_fold = make_folds(X,y,n=n, id_column=id_column)\n",
    "    for j in tqdm(range(n)):\n",
    "        X_control = X_control_main.copy()\n",
    "        X_train, y_train = pd.concat([X_fold[k] for k in range(len(X_fold)) if k!=j]),pd.concat([y_fold[k] for k in range(len(X_fold)) if k!=j])\n",
    "        X_test,y_test = X_fold[j].copy(), y_fold[j].copy()    \n",
    "\n",
    "        X_train, X_test, X_control = first_round(X_train, X_test, X_control)\n",
    "\n",
    "        print(f'FOLD {j}')\n",
    "        print(f'First round selection: {X_train.columns.size} features')\n",
    "\n",
    "        for func in second_round:\n",
    "            X_train_c = X_train.copy()\n",
    "            X_test_c = X_test.copy()\n",
    "            X_control_c = X_control.copy()\n",
    "            if func.__name__ in ['permut', 'greedy']:\n",
    "                kwargs = {'id_column': id_column}\n",
    "            else:\n",
    "                kwargs = {}\n",
    "            try:\n",
    "                X_train, X_test, X_control = func(X_train, y_train,X_test, y_test, X_control, **kwargs)\n",
    "                print(f'Second round selection: {X_train.columns.size} features ({func.__name__})')\n",
    "                res[f'split_{s}'][func.__name__]['n_features'].append(X_train.columns.size)\n",
    "            except:\n",
    "                for model_name in ['lr', 'svm', 'rf', 'xgb']:\n",
    "                    res = write_dict(res, f'split_{s}', func.__name__, model_name, y_test, X_test, \n",
    "                                     y_control, X_control, None, fillna=True)\n",
    "                    res[f'split_{s}'][func.__name__]['n_features'].append(float('nan'))\n",
    "                continue\n",
    "\n",
    "            for model_name in ['lr', 'svm', 'rf', 'xgb']:\n",
    "                try:\n",
    "                    if model_name == 'svm':\n",
    "                        dict_concat = {'probability':True}\n",
    "                        X_train_non = X_train.copy()\n",
    "                        X_test_non = X_test.copy()\n",
    "                        X_control_non = X_control.copy()\n",
    "                        X_train, y_train, X_test, y_test, scaler = normalization(X_train, y_train, X_test, y_test)\n",
    "                        X_control.loc[:, :] = scaler.transform(X_control)\n",
    "                    else:\n",
    "                        dict_concat = {}\n",
    "                    print(model_name)\n",
    "\n",
    "                    clf = hp_model(model_name, X_train, y_train, evals=15, max_iterations=51,metric=roc_auc_score, \n",
    "                                  dict_concat=dict_concat, id_column=id_column, oversampling=False, random_state=42, \n",
    "                                  class_w='balanced', n_folds=4, thr_diff=0.2, thr_min=0.6, print_scores=False)\n",
    "                    res = write_dict(res, f'split_{s}', func.__name__, model_name, y_test, X_test, \n",
    "                                     y_control, X_control, clf, fillna=False)\n",
    "                    X_train, X_test, X_control =  X_train_non.copy(), X_test_non.copy(), X_control_non.copy()\n",
    "                except:\n",
    "                    res = write_dict(res, f'split_{s}', func.__name__, model_name, y_test, X_test, \n",
    "                                     y_control, X_control, None, fillna=True)\n",
    "                    continue\n",
    "                \n",
    "                with open('results.json', 'w+') as f:\n",
    "                    json.dump(res, f)\n",
    "                X_train, X_test, X_control = X_train_c.copy(), X_test_c.copy(), X_control_c.copy() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = res.copy()\n",
    "res = {k:v for k,v in res.items() if k in ['split_0','split_1','split_2',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res = {'lr':{},'svm':{},'rf':{},'xgb':{}}\n",
    "for s in [f'split_{i}' for i in range(3)]:\n",
    "    for f in [func.__name__ for func in second_round]:\n",
    "        for m in ['lr', 'svm', 'rf', 'xgb']:\n",
    "            try:\n",
    "                len(new_res[m][f])\n",
    "            except:\n",
    "                new_res[m][f] = []\n",
    "            new_res[m][f].append(res[s][f][m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res = {'lr':{},'svm':{},'rf':{},'xgb':{}}\n",
    "for s in [f'split_{i}' for i in range(3)]:\n",
    "    df = pd.DataFrame()\n",
    "    for f in [func.__name__ for func in second_round]:\n",
    "        for m in ['lr', 'svm', 'rf', 'xgb']:\n",
    "            try:\n",
    "                new_res[m][f].iloc[0,:]\n",
    "            except:\n",
    "                new_res[m][f] = pd.DataFrame()\n",
    "            new_res[m][f] = pd.concat([new_res[m][f],pd.DataFrame(pd.DataFrame(res[s]).loc[m, f]).mean()],axis=1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for m in ['lr', 'svm', 'rf', 'xgb']:\n",
    "    a = []\n",
    "    for f in [func.__name__ for func in second_round]:\n",
    "        a.append(new_res[m][f].apply(lambda x: np.mean(x),axis=1))\n",
    "    dfs[m] = pd.DataFrame(a,index=[func.__name__ for func in second_round]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = deepcopy(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('results.json', 'r+') as f:\n",
    "    res = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs1 = {}\n",
    "for m in ['lr', 'svm', 'rf', 'xgb']:\n",
    "    a = []\n",
    "    for f in [func.__name__ for func in second_round]:\n",
    "        a.append(new_res[m][f].apply(lambda x: np.std(x),axis=1))\n",
    "    dfs1[m] = pd.DataFrame(a,index=[func.__name__ for func in second_round]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "\n",
    "s.append([\n",
    "'acc test & 0.805 $\\pm$ 0.017 & 0.9103 $\\pm$ 0.008 & 0.8152 $\\pm$ 0.013 & 0.4091 $\\pm$ 0.01 & 0.7778 $\\pm$ 0.016 & 0.8078 $\\pm$ 0.01',\n",
    "\n",
    "'auc test & 0.9044 $\\pm$ 0.025 & 0.972 $\\pm$ 0.006 & 0.8998 $\\pm$ 0.032 & 0.5 $\\pm$ 0.0 & 0.885 $\\pm$ 0.016 & 0.9143 $\\pm$ 0.017 ',\n",
    "\n",
    "'acc control & 0.5082 & 0.8175 & 0.6054 & 0.4025 & 0.5265 & 0.7066 ',\n",
    "\n",
    "'auc control & 0.7017 & 0.9607 & 0.704 & 0.5042 & 0.6922 & 0.7977 ',\n",
    "])\n",
    "\n",
    "s.append([\n",
    "'acc test & 0.9084 $\\pm$ 0.017 & 0.8914 $\\pm$ 0.034 & 0.9276 $\\pm$ 0.003 & 0.4266 $\\pm$ 0.02 & 0.9082 $\\pm$ 0.018 & 0.9026 $\\pm$ 0.015 ',\n",
    "\n",
    "'auc test & 0.9739 $\\pm$ 0.011 & 0.9721 $\\pm$ 0.01 & 0.9851 $\\pm$ 0.007 & 0.5 $\\pm$ 0.0 & 0.9727 $\\pm$ 0.009 & 0.9767 $\\pm$ 0.011 ',\n",
    "\n",
    "'acc control & 0.8438 & 0.841 & \\textbf{0.8904} & 0.4158 & 0.8363 & \\textbf{0.8724} ',\n",
    "\n",
    "'auc control & 0.9742 & 0.966 & \\textbf{0.9819} & 0.5 & 0.9716 & \\textbf{0.9761} ',\n",
    "])\n",
    "\n",
    "s.append([\n",
    "'acc test & 0.8905 $\\pm$ 0.014 & 0.8809 $\\pm$ 0.017 & 0.878 $\\pm$ 0.016 & 0.5242 $\\pm$ 0.044 & 0.8938 $\\pm$ 0.016 & 0.889 $\\pm$ 0.016',\n",
    "\n",
    "'auc test & 0.9649 $\\pm$ 0.007 & 0.9491 $\\pm$ 0.013 & 0.9732 $\\pm$ 0.011 & 0.5221 $\\pm$ 0.072 & 0.9641 $\\pm$ 0.009 & 0.9744 $\\pm$ 0.009',\n",
    "\n",
    "'acc control & 0.7323 & 0.7062 & 0.753 & 0.5149 & 0.733 & 0.7492',\n",
    "\n",
    "'auc control & 0.9448 & 0.8825 & 0.9371 & 0.4681 & 0.9462 & 0.9394',\n",
    "])\n",
    "\n",
    "s.append([\n",
    "'acc test & 0.8733 $\\pm$ 0.023 & 0.8536 $\\pm$ 0.023 & 0.858 $\\pm$ 0.022 & 0.4928 $\\pm$ 0.042 & 0.8708 $\\pm$ 0.019 & 0.8677 $\\pm$ 0.022',\n",
    "\n",
    "'auc test & 0.9636 $\\pm$ 0.02 & 0.9428 $\\pm$ 0.01 & 0.9429 $\\pm$ 0.017 & 0.5229 $\\pm$ 0.053 & 0.958 $\\pm$ 0.019 & 0.9691 $\\pm$ 0.017',\n",
    "\n",
    "'acc control & 0.8191 & 0.7371 & 0.7283 & 0.4969 & 0.8325 & 0.7645',\n",
    "\n",
    "'auc control & 0.9407 & 0.893 & 0.8893 & 0.4599 & 0.9428 & 0.9133',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reses = []\n",
    "for df in dfs:\n",
    "    sample = dfs[df].apply(lambda x: np.round(x,4)).astype('str')\n",
    "    sample2 = dfs1[df].apply(lambda x: np.round(x,3)).astype('str')\n",
    "    sample.iloc[:2,:] += ' +- '\n",
    "    sample.iloc[:2,:] += sample2.iloc[:2,:]\n",
    "    display(sample)\n",
    "    reses.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        a = s[i][j].split(' & ')\n",
    "        a[4] = reses[i].iloc[j,0]\n",
    "        print(' & '.join(a).replace('+-', '$\\pm$') + ' \\\\' + '\\\\')\n",
    "        print('\\\\hline')\n",
    "    print('#####################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res = {'n_features':{}}\n",
    "for s in [f'split_{i}' for i in range(3)]:\n",
    "    for f in [func.__name__ for func in second_round]:\n",
    "        for m in ['n_features']:\n",
    "            try:\n",
    "                len(new_res[m][f])\n",
    "            except:\n",
    "                new_res[m][f] = []\n",
    "            new_res[m][f].append(res[s][f][m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for m in ['n_features']:\n",
    "    a = []\n",
    "    for f in [func.__name__ for func in second_round]:\n",
    "        a.append(new_res[m][f].apply(lambda x: np.mean(x),axis=1))\n",
    "    dfs[m] = pd.DataFrame(a,index=[func.__name__ for func in second_round]).T\n",
    "    display(dfs[m])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
