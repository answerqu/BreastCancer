{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score, confusion_matrix,accuracy_score\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.preprocessing import *\n",
    "from functions.functions import *\n",
    "from functions.df_modifications import *\n",
    "from functions.feature_selection import *\n",
    "from functions.other import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_df = 'vl'\n",
    "type_of_mask = 'v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'data/TG_{type_of_df}.csv', index_col = 0)\n",
    "df.columns = [col.replace('__gen', '') for col in df.columns]\n",
    "df.index = [ind.replace('_pat','').replace('_non','') for ind in df.index]\n",
    "df['id'] = df.index.map(lambda x: x.split('_')[0] + '_' + x.split('_')[1])\n",
    "df1 = df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.copy()\n",
    "df_non_symm = df[(df.f_1_1_1__right__v1 != df.f_1_1_1__left__v1) | (df.pathology == 0)]\n",
    "df_symm = df[(df.f_1_1_1__right__v1 == df.f_1_1_1__v1).values & (df.f_1_1_1__left__v1 == df.f_1_1_1__v1).values]\n",
    "\n",
    "df_non_symm = split_areas(df_non_symm)\n",
    "df_symm = split_areas(df_symm)\n",
    "df_symm = df_symm.loc[[ind for ind in df_symm.index if ind.find('right') != -1], :]\n",
    "\n",
    "df = pd.concat([df_symm,df_non_symm],axis=0)\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = ['PAC_69','PAC_48','PAC_14','PAC_65','PAC_63','PAC_66','PAC_61','PAC_64','PAC_62']\n",
    "#df = df[[col for col in df.columns if col.find('f_1') != -1 or col.find('f_4') != -1 ] + ['id', 'pathology']]\n",
    "df_test = df[df.id.isin(test_id)]\n",
    "df = df.drop(df_test.index)\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pathology\n",
    "X = df.iloc[:,:-2]\n",
    "id_column = df.id\n",
    "\n",
    "y_control = df_test.pathology\n",
    "X_control = df_test.iloc[:,:-2]\n",
    "X1 = X.copy()\n",
    "\n",
    "#cols = [col for col in X.columns if col.find('f_3') == -1 and col.find('f_2') == -1]\n",
    "\n",
    "#X = X[cols]\n",
    "#X_control = X_control[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_round(X_train, X_test, X_control):\n",
    "    X_train,q1 = variance(X_train)\n",
    "    X_train,q2 = outliers(X_train)\n",
    "    X_train = correlation(X_train, thr=0.95)\n",
    "    return X_train, X_test[X_train.columns], X_control[X_train.columns]\n",
    "\n",
    "\n",
    "second_round = [ttest, pca, permut, lr_selection, boruta_selection, greedy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_control_main = X_control.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n=5\n",
    "N=10\n",
    "\n",
    "res = {}\n",
    "for s in range(N):\n",
    "    res[f'split_{s}'] = {}\n",
    "    for func in second_round:\n",
    "        res[f'split_{s}'][func.__name__] = {}\n",
    "        for model_name in ['lr', 'svm', 'rf', 'xgb']:\n",
    "            res[f'split_{s}'][func.__name__][model_name] = {}\n",
    "            for metric in ['acc_test', 'auc_test', 'acc_control', 'auc_control']:\n",
    "                res[f'split_{s}'][func.__name__][model_name][metric] = []\n",
    "        res[f'split_{s}'][func.__name__]['n_features'] = []\n",
    "\n",
    "for s in tqdm(range(N)):   \n",
    "    X_fold, y_fold = make_folds(X,y,n=n, id_column=id_column)\n",
    "    for j in tqdm(range(n)):\n",
    "        X_control = X_control_main.copy()\n",
    "        X_train, y_train = pd.concat([X_fold[k] for k in range(len(X_fold)) if k!=j]),pd.concat([y_fold[k] for k in range(len(X_fold)) if k!=j])\n",
    "        X_test,y_test = X_fold[j].copy(), y_fold[j].copy()    \n",
    "\n",
    "        X_train, X_test, X_control = first_round(X_train, X_test, X_control)\n",
    "\n",
    "        print(f'FOLD {j}')\n",
    "        print(f'First round selection: {X_train.columns.size} features')\n",
    "\n",
    "        for func in second_round:\n",
    "            X_train_c = X_train.copy()\n",
    "            X_test_c = X_test.copy()\n",
    "            X_control_c = X_control.copy()\n",
    "            #kwargs = {'id_column': id_column}\n",
    "            try:\n",
    "                X_train, X_test, X_control = func(X_train, y_train,X_test, y_test, X_control)\n",
    "                print(f'Second round selection: {X_train.columns.size} features ({func.__name__})')\n",
    "                res[f'split_{s}'][func.__name__]['n_features'].append(X_train.columns.size)\n",
    "            except:\n",
    "                for model_name in ['lr', 'svm', 'rf', 'xgb']:\n",
    "                    res = write_dict(res, f'split_{s}', func.__name__, model_name, y_test, X_test, \n",
    "                                     y_control, X_control, None, fillna=True)\n",
    "                    res[f'split_{s}'][func.__name__]['n_features'].append(float('nan'))\n",
    "                continue\n",
    "\n",
    "            for model_name in ['lr', 'svm', 'rf', 'xgb']:\n",
    "                try:\n",
    "                    if model_name == 'svm':\n",
    "                        dict_concat = {'probability':True}\n",
    "                        X_train_non = X_train.copy()\n",
    "                        X_test_non = X_test.copy()\n",
    "                        X_control_non = X_control.copy()\n",
    "                        X_train, y_train, X_test, y_test, scaler = normalization(X_train, y_train, X_test, y_test)\n",
    "                        X_control.loc[:, :] = scaler.transform(X_control)\n",
    "                    else:\n",
    "                        dict_concat = {}\n",
    "                    print(model_name)\n",
    "\n",
    "                    clf = hp_model(model_name, X_train, y_train, evals=15, max_iterations=51,metric=roc_auc_score, \n",
    "                                  dict_concat=dict_concat, id_column=id_column, oversampling=False, random_state=42, \n",
    "                                  class_w='balanced', n_folds=4, thr_diff=0.2, thr_min=0.6, print_scores=False)\n",
    "                    res = write_dict(res, f'split_{s}', func.__name__, model_name, y_test, X_test, \n",
    "                                     y_control, X_control, clf, fillna=False)\n",
    "                    X_train, X_test, X_control =  X_train_non.copy(), X_test_non.copy(), X_control_non.copy()\n",
    "                except:\n",
    "                    res = write_dict(res, f'split_{s}', func.__name__, model_name, y_test, X_test, \n",
    "                                     y_control, X_control, None, fillna=True)\n",
    "                    continue\n",
    "                \n",
    "                with open('results.json', 'w+') as f:\n",
    "                    json.dump(res, f)\n",
    "                X_train, X_test, X_control = X_train_c.copy(), X_test_c.copy(), X_control_c.copy() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = res.copy()\n",
    "res = {k:v for k,v in res.items() if k in ['split_0','split_1','split_2',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res = {'lr':{},'svm':{},'rf':{},'xgb':{}}\n",
    "for s in [f'split_{i}' for i in range(3)]:\n",
    "    for f in [func.__name__ for func in second_round]:\n",
    "        for m in ['lr', 'svm', 'rf', 'xgb']:\n",
    "            try:\n",
    "                len(new_res[m][f])\n",
    "            except:\n",
    "                new_res[m][f] = []\n",
    "            new_res[m][f].append(res[s][f][m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res = {'lr':{},'svm':{},'rf':{},'xgb':{}}\n",
    "for s in [f'split_{i}' for i in range(3)]:\n",
    "    df = pd.DataFrame()\n",
    "    for f in [func.__name__ for func in second_round]:\n",
    "        for m in ['lr', 'svm', 'rf', 'xgb']:\n",
    "            try:\n",
    "                new_res[m][f].iloc[0,:]\n",
    "            except:\n",
    "                new_res[m][f] = pd.DataFrame()\n",
    "            new_res[m][f] = pd.concat([new_res[m][f],pd.DataFrame(pd.DataFrame(res[s]).loc[m, f]).mean()],axis=1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for m in ['lr', 'svm', 'rf', 'xgb']:\n",
    "    a = []\n",
    "    for f in [func.__name__ for func in second_round]:\n",
    "        a.append(new_res[m][f].apply(lambda x: np.mean(x),axis=1))\n",
    "    dfs[m] = pd.DataFrame(a,index=[func.__name__ for func in second_round]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = deepcopy(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('results.json', 'r+') as f:\n",
    "    res = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs1 = {}\n",
    "for m in ['lr', 'svm', 'rf', 'xgb']:\n",
    "    a = []\n",
    "    for f in [func.__name__ for func in second_round]:\n",
    "        a.append(new_res[m][f].apply(lambda x: np.std(x),axis=1))\n",
    "    dfs1[m] = pd.DataFrame(a,index=[func.__name__ for func in second_round]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "\n",
    "s.append([\n",
    "'acc test & 0.805 $\\pm$ 0.017 & 0.9103 $\\pm$ 0.008 & 0.8152 $\\pm$ 0.013 & 0.4091 $\\pm$ 0.01 & 0.7778 $\\pm$ 0.016 & 0.8078 $\\pm$ 0.01',\n",
    "\n",
    "'auc test & 0.9044 $\\pm$ 0.025 & 0.972 $\\pm$ 0.006 & 0.8998 $\\pm$ 0.032 & 0.5 $\\pm$ 0.0 & 0.885 $\\pm$ 0.016 & 0.9143 $\\pm$ 0.017 ',\n",
    "\n",
    "'acc control & 0.5082 & 0.8175 & 0.6054 & 0.4025 & 0.5265 & 0.7066 ',\n",
    "\n",
    "'auc control & 0.7017 & 0.9607 & 0.704 & 0.5042 & 0.6922 & 0.7977 ',\n",
    "])\n",
    "\n",
    "s.append([\n",
    "'acc test & 0.9084 $\\pm$ 0.017 & 0.8914 $\\pm$ 0.034 & 0.9276 $\\pm$ 0.003 & 0.4266 $\\pm$ 0.02 & 0.9082 $\\pm$ 0.018 & 0.9026 $\\pm$ 0.015 ',\n",
    "\n",
    "'auc test & 0.9739 $\\pm$ 0.011 & 0.9721 $\\pm$ 0.01 & 0.9851 $\\pm$ 0.007 & 0.5 $\\pm$ 0.0 & 0.9727 $\\pm$ 0.009 & 0.9767 $\\pm$ 0.011 ',\n",
    "\n",
    "'acc control & 0.8438 & 0.841 & \\textbf{0.8904} & 0.4158 & 0.8363 & \\textbf{0.8724} ',\n",
    "\n",
    "'auc control & 0.9742 & 0.966 & \\textbf{0.9819} & 0.5 & 0.9716 & \\textbf{0.9761} ',\n",
    "])\n",
    "\n",
    "s.append([\n",
    "'acc test & 0.8905 $\\pm$ 0.014 & 0.8809 $\\pm$ 0.017 & 0.878 $\\pm$ 0.016 & 0.5242 $\\pm$ 0.044 & 0.8938 $\\pm$ 0.016 & 0.889 $\\pm$ 0.016',\n",
    "\n",
    "'auc test & 0.9649 $\\pm$ 0.007 & 0.9491 $\\pm$ 0.013 & 0.9732 $\\pm$ 0.011 & 0.5221 $\\pm$ 0.072 & 0.9641 $\\pm$ 0.009 & 0.9744 $\\pm$ 0.009',\n",
    "\n",
    "'acc control & 0.7323 & 0.7062 & 0.753 & 0.5149 & 0.733 & 0.7492',\n",
    "\n",
    "'auc control & 0.9448 & 0.8825 & 0.9371 & 0.4681 & 0.9462 & 0.9394',\n",
    "])\n",
    "\n",
    "s.append([\n",
    "'acc test & 0.8733 $\\pm$ 0.023 & 0.8536 $\\pm$ 0.023 & 0.858 $\\pm$ 0.022 & 0.4928 $\\pm$ 0.042 & 0.8708 $\\pm$ 0.019 & 0.8677 $\\pm$ 0.022',\n",
    "\n",
    "'auc test & 0.9636 $\\pm$ 0.02 & 0.9428 $\\pm$ 0.01 & 0.9429 $\\pm$ 0.017 & 0.5229 $\\pm$ 0.053 & 0.958 $\\pm$ 0.019 & 0.9691 $\\pm$ 0.017',\n",
    "\n",
    "'acc control & 0.8191 & 0.7371 & 0.7283 & 0.4969 & 0.8325 & 0.7645',\n",
    "\n",
    "'auc control & 0.9407 & 0.893 & 0.8893 & 0.4599 & 0.9428 & 0.9133',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reses = []\n",
    "for df in dfs:\n",
    "    sample = dfs[df].apply(lambda x: np.round(x,4)).astype('str')\n",
    "    sample2 = dfs1[df].apply(lambda x: np.round(x,3)).astype('str')\n",
    "    sample.iloc[:2,:] += ' +- '\n",
    "    sample.iloc[:2,:] += sample2.iloc[:2,:]\n",
    "    display(sample)\n",
    "    reses.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        a = s[i][j].split(' & ')\n",
    "        a[4] = reses[i].iloc[j,0]\n",
    "        print(' & '.join(a).replace('+-', '$\\pm$') + ' \\\\' + '\\\\')\n",
    "        print('\\\\hline')\n",
    "    print('#####################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res = {'n_features':{}}\n",
    "for s in [f'split_{i}' for i in range(3)]:\n",
    "    for f in [func.__name__ for func in second_round]:\n",
    "        for m in ['n_features']:\n",
    "            try:\n",
    "                len(new_res[m][f])\n",
    "            except:\n",
    "                new_res[m][f] = []\n",
    "            new_res[m][f].append(res[s][f][m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for m in ['n_features']:\n",
    "    a = []\n",
    "    for f in [func.__name__ for func in second_round]:\n",
    "        a.append(new_res[m][f].apply(lambda x: np.mean(x),axis=1))\n",
    "    dfs[m] = pd.DataFrame(a,index=[func.__name__ for func in second_round]).T\n",
    "    display(dfs[m])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
